# University Data Ingestion & Verification Engine

**Production-grade university admission data ingestion and verification system for B2B education platforms.**

## ğŸ¯ System Overview

This system fetches, validates, normalizes, and compares university admission-related data with a focus on Indian applicant requirements. It follows strict architectural principles to ensure data quality, safety, and compliance.

### Core Philosophy

- **Never hallucinate data** - Missing data is represented as `null`, never guessed
- **Silence is better than wrong data** - If data can't be verified, it's not published
- **AI is an assistant, not an authority** - AI is used for verification only, not as primary source
- **Deterministic code > AI guesses** - Parsers are deterministic, AI verifies ambiguity
- **Conservative and respectful** - All scraping is done with respectful delays and headers

## ğŸ—ï¸ Architecture

The system is built with clear separation of concerns across multiple layers:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (Control Panel)                  â”‚
â”‚  - Job Dashboard                                            â”‚
â”‚  - Diff Viewer                                              â”‚
â”‚  - Manual Approve/Reject                                    â”‚
â”‚  - Real-time status updates                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ HTTP API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BACKEND API                               â”‚
â”‚  - Firebase Functions / Cloud Run                            â”‚
â”‚  - Job Queue Management                                     â”‚
â”‚  - API endpoints                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              JOB LIFECYCLE MANAGER                           â”‚
â”‚  Orchestrates the complete pipeline                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              â”‚              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚   FETCHER    â”‚ â”‚   PARSER   â”‚ â”‚ VALIDATOR  â”‚
â”‚              â”‚ â”‚            â”‚ â”‚            â”‚
â”‚ - HTTP fetch â”‚ â”‚ - Extract  â”‚ â”‚ - Format   â”‚
â”‚ - Headers    â”‚ â”‚ - No guess â”‚ â”‚ - Dates    â”‚
â”‚ - Delays     â”‚ â”‚ - Null if  â”‚ â”‚ - Cross-   â”‚
â”‚ - Backoff    â”‚ â”‚   missing  â”‚ â”‚   field    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚               â”‚              â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   DIFF ENGINE   â”‚
              â”‚                 â”‚
              â”‚ - Compare       â”‚
              â”‚ - Field diffs   â”‚
              â”‚ - Confidence    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  AI VERIFIER    â”‚
              â”‚                 â”‚
              â”‚ - Secondary     â”‚
              â”‚ - Confidence    â”‚
              â”‚ - Flag review   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   PUBLISHER     â”‚
              â”‚                 â”‚
              â”‚ - Batch writes  â”‚
              â”‚ - Version hist  â”‚
              â”‚ - Audit logs    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Layer Responsibilities

#### 1. Fetcher Layer
- **Purpose**: Fetch raw data from university websites
- **Methods**: `fetch()` API only (no headless browsers)
- **Features**:
  - Respectful headers (human-like User-Agent)
  - Sequential execution (one page at a time)
  - Configurable delays (5-10 seconds default)
  - Automatic backoff on errors
  - Blocks on 403/429 (no retry)

#### 2. Parser Layer
- **Purpose**: Extract structured fields from HTML/PDF
- **Principles**:
  - If field not found â†’ return `null`
  - Never guess or hallucinate values
  - Preserve source metadata for every field
- **Output**: Structured `Program` objects with optional fields

#### 3. Validator Layer
- **Purpose**: Ensure data format correctness
- **Checks**:
  - Date sanity (future dates, valid formats)
  - Format validation (currency, scores, percentages)
  - Cross-field consistency (IELTS/TOEFL correlation, fee relationships)
- **Output**: Valid/invalid programs with error details

#### 4. Diff Engine
- **Purpose**: Compare previous vs new data
- **Features**:
  - Field-by-field comparison
  - Change detection (unchanged, changed, missing, newly added)
  - Confidence scoring
  - Flags changes requiring review
- **Output**: `ProgramDiff` objects with change details

#### 5. AI Verification Layer
- **Purpose**: Secondary verification of ambiguous data
- **Constraints**:
  - AI is used ONLY for verification, not generation
  - Only verifies low-confidence or conflicting fields
  - Updates confidence scores
  - Flags fields needing manual review
- **Output**: Verified programs with updated confidence scores

#### 6. Publisher Layer
- **Purpose**: Write verified data to Firestore
- **Features**:
  - Batch writes (efficient)
  - Version history (track changes over time)
  - Audit logs (who approved, when)
  - Only publishes after manual approval (by default)
- **Output**: Published programs in Firestore

## ğŸ”„ Job Lifecycle

Every data fetch follows this state machine:

```
QUEUED â†’ FETCHING â†’ PARSING â†’ VALIDATING â†’ DIFFING â†’ AI_VERIFYING â†’ READY_TO_PUBLISH â†’ PUBLISHED
                                                                                            â†“
                                                                                        FAILED
                                                                                            â†“
                                                                                    FAILED_BLOCKED
```

### State Descriptions

- **QUEUED**: Job created, waiting in queue
- **FETCHING**: Downloading data from URLs
- **PARSING**: Extracting structured fields
- **VALIDATING**: Checking format and consistency
- **DIFFING**: Comparing with previous data
- **AI_VERIFYING**: AI verification (if enabled)
- **READY_TO_PUBLISH**: Waiting for manual approval
- **PUBLISHED**: Approved and written to Firestore
- **FAILED**: Error occurred (retryable)
- **FAILED_BLOCKED**: Rate limited/blocked (requires manual review)

## ğŸ”’ Safety & Compliance

### Hard Constraints

**DO NOT use any method that:**
- Blocks URLs or triggers bot protection
- Violates robots.txt
- Causes IP bans
- Risks domain suspension

**ONLY ALLOWED methods:**
- Public university webpages (HTML fetch)
- Public PDFs
- Public APIs (if available)
- Official university portals with public access

**ABSOLUTELY FORBIDDEN:**
- Headless browsers (Puppeteer, Playwright)
- Aggressive crawling
- Parallel hammering
- Cloudflare bypass tricks
- CAPTCHA solving
- Proxy rotation

### Rate Limiting

- **Default delay**: 7.5 seconds between requests
- **Between universities**: 10 seconds
- **Automatic backoff**: Exponential backoff on retries
- **Blocked requests**: Marked as `FAILED_BLOCKED`, no automatic retry

### Configuration

All rate limiting is configurable via environment variables (see `backend/.env.example`):

```bash
DELAY_BETWEEN_REQUESTS=7500      # ms
DELAY_BETWEEN_UNIVERSITIES=10000 # ms
MAX_RETRIES=3
BACKOFF_MULTIPLIER=2.0
```

## ğŸ“Š Data Model

### Core Types

All data is strongly typed with TypeScript interfaces:

- **University**: Basic university information
- **Program**: Complete program data with source tracking
- **Intake**: Term/year information with deadlines
- **Deadline**: Individual deadline with source metadata
- **FetchJob**: Job lifecycle tracking
- **ProgramDiff**: Field-by-field change detection
- **ConfidenceScore**: Confidence breakdown
- **AuditLog**: Action tracking

### Source Tracking

Every field stores:
- **value**: The actual data
- **source**: Source metadata including:
  - `sourceUrl`: URL where data was found
  - `fetchedAt`: Timestamp
  - `confidenceScore`: 0-100 confidence
  - `verificationMethod`: `direct` | `inferred` | `ai_verified`

This enables full traceability and auditability.

## ğŸš€ Getting Started

### Prerequisites

- Node.js 18+
- Firebase project
- Gemini API key (for AI verification, optional)

### Installation

1. **Install frontend dependencies**:
   ```bash
   npm install
   ```

2. **Install backend dependencies**:
   ```bash
   cd backend
   npm install
   ```

3. **Configure Firebase**:
   - Update `firebase.ts` with your Firebase config
   - Set up Firestore collections:
     - `fetch_jobs`
     - `university_programs`
     - `program_versions`
     - `audit_logs`
     - `diff_results`

4. **Configure environment**:
   - Copy `backend/.env.example` to `backend/.env`
   - Fill in your configuration

### Running Locally

1. **Start backend** (Firebase Functions emulator or Cloud Run):
   ```bash
   cd backend
   npm run dev
   ```

2. **Start frontend**:
   ```bash
   npm run dev
   ```

3. **Access frontend**: http://localhost:3000

### Deployment

#### Firebase Functions

```bash
cd backend
npm run build
firebase deploy --only functions
```

#### Cloud Run

```bash
cd backend
npm run build
gcloud run deploy
```

## ğŸ“ Usage

### Creating a Job

1. Use the frontend UI to create a new job
2. Or call the API directly:

```bash
POST /jobs/create
{
  "universityName": "University of Toronto",
  "country": "Canada",
  "urls": ["https://www.utoronto.ca/admissions"],
  "autoPublish": false,
  "createdBy": "user"
}
```

### Manual Approval

1. Jobs reach `READY_TO_PUBLISH` state
2. Review diffs in the frontend
3. Approve or reject changes
4. Only approved data is published to Firestore

### Monitoring

- Job status is visible in real-time via Firestore subscriptions
- All actions are logged in audit logs
- Failed jobs are marked and require review

## ğŸ” Observability

### Structured Logging

All operations log structured JSON:

```json
{
  "timestamp": "2024-01-15T10:30:00Z",
  "level": "info",
  "message": "Job execution complete",
  "context": {
    "jobId": "job_123",
    "status": "READY_TO_PUBLISH",
    "duration": 45000,
    "programsFound": 5
  }
}
```

### Log Levels

- **debug**: Detailed debugging information
- **info**: General information
- **warn**: Warning messages
- **error**: Error conditions
- **critical**: Critical failures

### Metrics to Monitor

- Fetch duration
- Parse success rate
- Validation failure rate
- AI verification disagreements
- Change frequency per university
- Blocked request rate

## ğŸ› ï¸ Development

### Project Structure

```
.
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ layers/          # Core processing layers
â”‚   â”‚   â”œâ”€â”€ fetcher.ts
â”‚   â”‚   â”œâ”€â”€ parser.ts
â”‚   â”‚   â”œâ”€â”€ validator.ts
â”‚   â”‚   â”œâ”€â”€ diff-engine.ts
â”‚   â”‚   â”œâ”€â”€ ai-verifier.ts
â”‚   â”‚   â””â”€â”€ publisher.ts
â”‚   â”œâ”€â”€ job/             # Job management
â”‚   â”‚   â”œâ”€â”€ job-manager.ts
â”‚   â”‚   â””â”€â”€ job-queue.ts
â”‚   â”œâ”€â”€ utils/           # Utilities
â”‚   â”‚   â”œâ”€â”€ logger.ts
â”‚   â”‚   â””â”€â”€ delay.ts
â”‚   â”œâ”€â”€ config.ts        # Configuration
â”‚   â””â”€â”€ index.ts         # Entry point
â”œâ”€â”€ components/          # React components
â”‚   â”œâ”€â”€ JobDashboard.tsx
â”‚   â”œâ”€â”€ DiffViewer.tsx
â”‚   â””â”€â”€ Layout.tsx
â”œâ”€â”€ services/            # Frontend services
â”‚   â”œâ”€â”€ api.ts
â”‚   â””â”€â”€ jobService.ts
â”œâ”€â”€ types/               # TypeScript types
â”‚   â””â”€â”€ core.ts
â””â”€â”€ utils/               # Frontend utilities
    â””â”€â”€ universityUrls.ts
```

### Adding a New Parser

1. Create a parser class in `backend/layers/parser.ts`
2. Follow the principle: return `null` if data not found
3. Always preserve source metadata
4. Add validation rules if needed

### Extending Data Model

1. Update `types/core.ts` with new interfaces
2. Update parser to extract new fields
3. Update validator to validate new fields
4. Update diff engine to compare new fields
5. Update frontend to display new fields

## âš ï¸ Important Notes

### Production Considerations

1. **URL Management**: Maintain a database of verified URLs per university
2. **Parser Sophistication**: Current parsers are basic - enhance with proper HTML parsing libraries (cheerio, jsdom)
3. **AI Integration**: Complete the AI verification implementation with actual Gemini API calls
4. **Firestore Rules**: Set up proper security rules for Firestore
5. **Error Handling**: Enhance error handling for production edge cases
6. **Monitoring**: Set up Cloud Logging and monitoring alerts
7. **Backup**: Implement backup strategies for Firestore data

### Known Limitations

- Parser uses basic regex - needs enhancement
- AI verification is mocked - needs real API integration
- URL discovery is basic - needs proper domain mapping
- Frontend diff viewer needs Firestore integration

## ğŸ“„ License

[Your License Here]

## ğŸ¤ Contributing

[Contributing Guidelines]

---

**Built with production-grade principles. Designed for trust and reliability.**
